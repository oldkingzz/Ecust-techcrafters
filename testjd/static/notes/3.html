<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>2-intro</title>
  </head>
<h1 id="机器学习基本概念">3. 机器学习基本概念</h1>
<h3 id="回归">回归</h3>
<p>关于回归的问题我们在上一章中已经有过描述，我这里就不重复了。但作为反二次元吧的黄牌，我抛弃ppt上宝可梦的例子，换一个新的直观的例子。（宝可梦的例子很好，但是是二次元）</p>
<p>现在我举这么个例子，你要找到一个人在大学icpc/蓝桥杯/物理竞赛/数学竞赛的参赛成绩和他们二次元浓度的关系。现在你先数字化一个人的成绩（如国一为1，没有奖为10）以及他们二次元浓度（没救了为1，误入歧途为10)。然后你设定成绩为输入，二次元浓度为输出，然后你你通过机器学习算法和一定量的样本，得到了一个新的模型。这个模型可以通过输入成绩，判断二次元的浓度，这就是一个简单的机器学习模型。而且是一个很典型的回归模型（注意，不是多分类）</p>
<h3 id="机器学习的步骤">机器学习的步骤</h3>
<p>定义一组函数-&gt;评估函数的好坏&lt;-训练数据</p>
<p>这种情况下，我们“评估函数的好坏”的方法越高效，我们的机器学习的结果就越好。</p>
<p>那么该如何做呢？</p>
<p>步骤</p>
<ol class="incremental" type="1">
<li><strong>初始状态：</strong> 初始参数 b 和 w
随机设定。你的损失函数（MSE）为一个初始值，表示模型在初始参数下的预测与实际值之间的平均差异。</li>
<li><strong>第一次迭代：</strong> 使用梯度下降法，计算损失函数对 b 和 w
的偏导数，得到一个梯度向量。根据学习率，你将每个参数按照梯度的方向和大小进行调整。这会导致参数
b 和 w
发生变化，从而改变了函数的形状。随着参数的更新，损失函数的值会减小。</li>
<li><strong>第二次迭代：</strong>
继续使用梯度下降法，计算新参数下的损失函数。这一次，损失函数的值可能更接近于实际数据，因为模型已经根据上一次迭代的调整更好地拟合了数据。</li>
<li><strong>多次迭代：</strong>
你不断重复上述步骤，每次迭代中都计算新的参数值和相应的损失函数。随着迭代的进行，损失函数的值会逐渐减小，这表示模型在不断优化，预测结果与实际值越来越接近。</li>
<li><strong>收敛：</strong>
随着迭代次数的增加，损失函数可能会趋于稳定，不再大幅下降。此时，模型已经在参数空间中找到了一个局部最优解，使得预测值与实际值的差异最小。</li>
</ol>
<h4 id="损失函数衡量函数的好坏">损失函数衡量函数的好坏</h4>
<p>已知函数”y = b + w ∙ xcp”
x为输入，y为输出，损失函数接受w和b为输入，输出为一个数。这个数字越小，越高效</p>
<h4
id="梯度下降是寻找最佳函数的一种方法gradient-descent-is-a-method-for-finding-the-best-function">梯度下降是寻找最佳函数的一种方法（Gradient
descent is a method for finding the best function）</h4>
<p>以上问题中，有两个参数，分别是w和b，我们令w=θ₁,b=θ₂（用θₙ更直观而已）</p>
<p>在每一次迭代中：计算∇L(θ) = (∂L/∂, ∂L/∂θ₂, …,
∂L/∂θₙ)，这个时候我们就可以更新θ = θ - α * ∇L(θ)</p>
<p>这里面的α叫学习率，是个人为设定的值，我们后面再说</p>
<p>迭代很多次之后，梯度会很小，这时候就算收敛，也就是计算完成了</p>
<p>但是，怎么可能那么简单？</p>
<h4 id="过拟合与欠拟合">过拟合与欠拟合</h4>
<h6 id="欠拟合">欠拟合</h6>
<p>当模型欠拟合训练数据，它在训练集和测试集上都表现不太好，无法很好地捕捉数据的关系。</p>
<h6 id="过拟合">过拟合</h6>
<p>当模型过度拟合训练数据，它会在训练集上表现得很好，但在未见过的测试数据上表现较差。</p>
